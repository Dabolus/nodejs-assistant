[Assistant SDK for Node.js](../README.md) > [AssistantResponse](../interfaces/assistantresponse.md)

# Interface: AssistantResponse

## Hierarchy

**AssistantResponse**

## Index

### Properties

* [action](assistantresponse.md#action)
* [actionOnGoogle](assistantresponse.md#actionongoogle)
* [audio](assistantresponse.md#audio)
* [conversationEnded](assistantresponse.md#conversationended)
* [conversationState](assistantresponse.md#conversationstate)
* [html](assistantresponse.md#html)
* [newVolume](assistantresponse.md#newvolume)
* [speechRecognitionResults](assistantresponse.md#speechrecognitionresults)
* [text](assistantresponse.md#text)
* [utteranceEnded](assistantresponse.md#utteranceended)

---

## Properties

<a id="action"></a>

### `<Optional>` action

**● action**: *`unknown`*

___
<a id="actionongoogle"></a>

### `<Optional>` actionOnGoogle

**● actionOnGoogle**: *`unknown`*

___
<a id="audio"></a>

### `<Optional>` audio

**● audio**: *`Buffer`*

___
<a id="conversationended"></a>

### `<Optional>` conversationEnded

**● conversationEnded**: *`boolean`*

___
<a id="conversationstate"></a>

### `<Optional>` conversationState

**● conversationState**: *`Buffer`*

___
<a id="html"></a>

### `<Optional>` html

**● html**: *`string`*

___
<a id="newvolume"></a>

### `<Optional>` newVolume

**● newVolume**: *`number`*

___
<a id="speechrecognitionresults"></a>

### `<Optional>` speechRecognitionResults

**● speechRecognitionResults**: *[AssistantSpeechRecognitionResult](assistantspeechrecognitionresult.md)[]*

___
<a id="text"></a>

### `<Optional>` text

**● text**: *`string`*

___
<a id="utteranceended"></a>

### `<Optional>` utteranceEnded

**● utteranceEnded**: *`boolean`*

___

